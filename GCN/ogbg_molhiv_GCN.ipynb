{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XuXWJLEm2UWS"
   },
   "source": [
    "# **Tutorial**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8gzsP50bF6Gb"
   },
   "source": [
    "In this notebook, we will work to construct our own graph neural network using PyTorch Geometric (PyG) and then apply that model on  Open Graph Benchmark (OGB) dataset. This dataset will be used to benchmark your model's performance on graph property prediction task: predicting properties of entire graphs or subgraphs.\n",
    "\n",
    "**Note**: Make sure to **sequentially run all the cells in each section**, so that the intermediate variables / packages will carry over to the next cell\n",
    "\n",
    "We recommend you to run this notebook in colab so you don't need to go through dependecies installations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGKqVEbbMEzf"
   },
   "source": [
    "# Device\n",
    "You might need to use a GPU for this Colab to run quickly.\n",
    "\n",
    "Please click `Runtime` and then `Change runtime type`. Then set the `hardware accelerator` to **GPU**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCK7krJdp4o8"
   },
   "source": [
    "# Setup\n",
    "Installation of PyG on Colab can be a little bit tricky. First let us check which version of PyTorch you are running. Copy the version of PyTorch and paste it to the url in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2vkP8pA1qBE5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7769a928-bacc-4584-e849-a1e03a11565d"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PyTorch has version 2.1.0+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "print(\"PyTorch has version {}\".format(torch.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L6d22O6DqGSZ"
   },
   "source": [
    "Download the necessary packages for PyG. Make sure that your version of torch matches the output from the cell above. In case of any issues, more information can be found on the [PyG's installation page](https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html)."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-2.1.0+cu118.html\n",
    "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-2.1.0+cu118.html\n",
    "!pip install torch-geometric\n",
    "!pip install ogb"
   ],
   "metadata": {
    "id": "e9jYvrWe14X4"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset downloading"
   ],
   "metadata": {
    "id": "zZiRG81hF_so"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch_geometric.transforms as T\n",
    "from ogb.graphproppred import PygGraphPropPredDataset\n",
    "\n",
    "dataset_name = 'ogbg-molhiv'\n",
    "# Load the dataset and transform it to sparse tensor\n",
    "dataset = PygGraphPropPredDataset(name=dataset_name,\n",
    "                                transform=T.ToSparseTensor())\n",
    "print('The {} dataset has {} graph'.format(dataset_name, len(dataset)))\n",
    "\n",
    "# Extract the graph\n",
    "print(\"Example of graph:\", dataset[0])\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# If you use GPU, the device should be cuda\n",
    "print('Device: {}'.format(device))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i8WrsKP1Jiqc",
    "outputId": "399711ad-b70a-4d90-dcaf-6a979d4c8a9f"
   },
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The ogbg-molhiv dataset has 41127 graph\n",
      "Example of graph: Data(edge_attr=[40, 3], x=[19, 9], y=[1, 1], num_nodes=19, adj_t=[19, 19, nnz=40])\n",
      "Device: cuda\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# GCN Model"
   ],
   "metadata": {
    "id": "Oca_n4DeGXBB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers,\n",
    "                 dropout):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        # A list of GCNConv layers\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(GCNConv(input_dim, hidden_dim))\n",
    "        for _ in range(num_layers -2):\n",
    "          self.convs.append(GCNConv(hidden_dim, hidden_dim))\n",
    "        self.convs.append(GCNConv(hidden_dim, output_dim))\n",
    "\n",
    "        # A list of 1D batch normalization layers\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers - 1):\n",
    "          self.bns.append(torch.nn.BatchNorm1d(hidden_dim))\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.linear = torch.nn.Linear(output_dim, 1)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t, batch):\n",
    "\n",
    "        out = None\n",
    "        for i in range(len(self.convs) - 1):\n",
    "          x = self.convs[i](x, adj_t)\n",
    "          x = self.bns[i](x)\n",
    "          x = F.relu(x)\n",
    "          x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = self.convs[len(self.convs) - 1](x, adj_t)\n",
    "        x = global_mean_pool(x, batch)\n",
    "\n",
    "        x = self.linear(x)\n",
    "        out = x\n",
    "\n",
    "        return out"
   ],
   "metadata": {
    "id": "CsJfXkPIOQyn"
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training arguments"
   ],
   "metadata": {
    "id": "MzikyYnYGdBI"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch_geometric.nn.pool import global_mean_pool\n",
    "from tqdm import tqdm\n",
    "\n",
    "split_idx = dataset.get_idx_split()\n",
    "train_loader = DataLoader(dataset[split_idx[\"train\"]], batch_size=64, shuffle=True)\n",
    "valid_loader = DataLoader(dataset[split_idx[\"valid\"]], batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(dataset[split_idx[\"test\"]], batch_size=64, shuffle=False)\n",
    "\n",
    "args = {\n",
    "      'device': device,\n",
    "      'num_layers': 5,\n",
    "      'hidden_dim': 512,\n",
    "      'dropout': 0.5,\n",
    "      'lr': 0.01,\n",
    "      'epochs': 30,\n",
    "      \"out_channels\": 128,\n",
    "  }\n",
    "\n",
    "model = GCN(dataset.num_node_features, args['hidden_dim'],\n",
    "            args[\"out_channels\"], args['num_layers'],\n",
    "            args['dropout']).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])"
   ],
   "metadata": {
    "id": "vVT907oHHqhT",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "dca8ab9a-b03c-41a5-bb80-9068a3f72aba"
   },
   "execution_count": 21,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train/eval functions"
   ],
   "metadata": {
    "id": "YKsaI0FvGkt-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "# Training loop\n",
    "def train():\n",
    "  model.train()\n",
    "  train_loss = []\n",
    "  for data in tqdm(train_loader, total=len(train_loader)):\n",
    "      optimizer.zero_grad()\n",
    "      data = data.to(device)\n",
    "      data.adj_t = data.adj_t.to_symmetric()\n",
    "      data.x = data.x.float()\n",
    "      out = model(data.x, data.adj_t, data.batch)\n",
    "      loss = criterion(out, data.y.view(-1, 1).to(torch.float32))\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      train_loss.append(loss.item())\n",
    "\n",
    "  return sum(train_loss)/len(train_loss)\n",
    "\n",
    "# Evaluation\n",
    "def evaluate(model, loader, display=False):\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "      y_true = []\n",
    "      y_pred = []\n",
    "      for data in loader:\n",
    "          data = data.to(device)\n",
    "          data.x = data.x.float()\n",
    "          data.adj_t = data.adj_t.to_symmetric()\n",
    "          out = model(data.x, data.adj_t, data.batch)\n",
    "          y_true.append(data.y.view(-1).cpu().numpy())\n",
    "          y_pred.append((out > 0.5).view(-1).cpu().numpy())\n",
    "\n",
    "  y_true = np.concatenate(y_true)\n",
    "  y_pred = np.concatenate(y_pred)\n",
    "\n",
    "  # Evaluate using appropriate metrics (e.g., accuracy, F1 score, ROC AUC)\n",
    "  if display:\n",
    "    print(f\"ROC AUC Score: {roc_auc_score(y_true, y_pred)}\")\n",
    "    print(f\"F1 Score: {f1_score(y_true, y_pred)}\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_true, y_pred)}\")\n",
    "  else:\n",
    "    return roc_auc_score(y_true, y_pred)"
   ],
   "metadata": {
    "id": "_Y6geBHZFmqo"
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "id": "fagMqHlKK_bU"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import copy\n",
    "best_model = None\n",
    "best_valid_roc_auc = 0\n",
    "for epoch in range(args[\"epochs\"]):\n",
    "  train_loss = train()\n",
    "  roc_auc_val = evaluate(model, valid_loader)\n",
    "  print(f\"Epoch #{epoch + 1}. Train Loss: {train_loss}. ROC_AUC_val: {roc_auc_val}\")\n",
    "  if roc_auc_val > best_valid_roc_auc:\n",
    "    best_valid_roc_auc = roc_auc_val\n",
    "    best_model = copy.deepcopy(model)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mT9Sc2KrYA1I",
    "outputId": "a6590cd3-c457-4655-ec6e-6ce308b05db9"
   },
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 515/515 [00:22<00:00, 22.97it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch #1. Train Loss: 0.18592179684529025. ROC_AUC_val: 0.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 515/515 [00:22<00:00, 22.87it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch #2. Train Loss: 0.15578844076908618. ROC_AUC_val: 0.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 515/515 [00:22<00:00, 22.69it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch #3. Train Loss: 0.15357059603104892. ROC_AUC_val: 0.5559000220458554\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 515/515 [00:22<00:00, 23.23it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch #4. Train Loss: 0.1515967304881626. ROC_AUC_val: 0.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 515/515 [00:21<00:00, 24.11it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch #5. Train Loss: 0.14920218694340256. ROC_AUC_val: 0.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 515/515 [00:21<00:00, 23.88it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch #6. Train Loss: 0.14720059062887741. ROC_AUC_val: 0.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 515/515 [00:22<00:00, 22.77it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch #7. Train Loss: 0.1460420221017981. ROC_AUC_val: 0.5481426366843034\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 515/515 [00:22<00:00, 23.34it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch #8. Train Loss: 0.1455311675818221. ROC_AUC_val: 0.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 515/515 [00:22<00:00, 23.25it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch #9. Train Loss: 0.14324428084695223. ROC_AUC_val: 0.5061728395061729\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 515/515 [00:21<00:00, 24.04it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch #10. Train Loss: 0.14204590580995802. ROC_AUC_val: 0.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 515/515 [00:21<00:00, 23.45it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch #11. Train Loss: 0.14202204871452548. ROC_AUC_val: 0.5185185185185185\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 515/515 [00:22<00:00, 22.83it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch #12. Train Loss: 0.1407237218602479. ROC_AUC_val: 0.49987599206349204\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 515/515 [00:22<00:00, 23.05it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch #13. Train Loss: 0.1407564827141542. ROC_AUC_val: 0.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 515/515 [00:22<00:00, 22.89it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch #14. Train Loss: 0.13989909892015664. ROC_AUC_val: 0.537037037037037\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 515/515 [00:21<00:00, 23.51it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch #15. Train Loss: 0.13876484247304283. ROC_AUC_val: 0.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 515/515 [00:23<00:00, 22.38it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch #16. Train Loss: 0.1381435959916381. ROC_AUC_val: 0.5123456790123457\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 515/515 [00:21<00:00, 23.45it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch #17. Train Loss: 0.13824860710397507. ROC_AUC_val: 0.5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 515/515 [00:22<00:00, 23.36it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch #18. Train Loss: 0.1374718436627712. ROC_AUC_val: 0.6035741843033509\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 515/515 [00:22<00:00, 22.87it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch #19. Train Loss: 0.1362828128293012. ROC_AUC_val: 0.5185185185185185\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 515/515 [00:22<00:00, 23.27it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch #20. Train Loss: 0.13628632044690905. ROC_AUC_val: 0.5302441578483246\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 515/515 [00:21<00:00, 24.00it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch #21. Train Loss: 0.1357616801646728. ROC_AUC_val: 0.49975198412698413\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 515/515 [00:21<00:00, 23.83it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch #22. Train Loss: 0.13618539322203801. ROC_AUC_val: 0.5308641975308642\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 515/515 [00:22<00:00, 22.80it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch #23. Train Loss: 0.1360282866302335. ROC_AUC_val: 0.5482666446208113\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 515/515 [00:22<00:00, 23.00it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch #24. Train Loss: 0.13582148599320823. ROC_AUC_val: 0.5491347001763669\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 515/515 [00:22<00:00, 23.17it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch #25. Train Loss: 0.13539949756441186. ROC_AUC_val: 0.5123456790123457\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 515/515 [00:23<00:00, 21.48it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch #26. Train Loss: 0.13408220889571223. ROC_AUC_val: 0.6399911816578483\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 515/515 [00:21<00:00, 23.71it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch #27. Train Loss: 0.13377767369802138. ROC_AUC_val: 0.536913029100529\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 515/515 [00:22<00:00, 23.39it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch #28. Train Loss: 0.13321246951818466. ROC_AUC_val: 0.5487626763668431\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 515/515 [00:22<00:00, 22.73it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch #29. Train Loss: 0.13240979595598087. ROC_AUC_val: 0.5792548500881834\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 515/515 [00:22<00:00, 22.64it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch #30. Train Loss: 0.1321655114949907. ROC_AUC_val: 0.5182705026455026\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Performance on validation dataset:\")\n",
    "evaluate(best_model, valid_loader, display=True)\n",
    "print(\"\\nPerformance on test dataset:\")\n",
    "evaluate(best_model, test_loader, display=True)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NNrvu8XWKlqV",
    "outputId": "bdcf660f-35a3-438c-f8c9-cfd94e8f3f46"
   },
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Performance on validation dataset:\n",
      "ROC AUC Score: 0.6399911816578483\n",
      "F1 Score: 0.3833333333333333\n",
      "Accuracy: 0.9820082664721614\n",
      "\n",
      "Performance on test dataset:\n",
      "ROC AUC Score: 0.5554327043782229\n",
      "F1 Score: 0.18404907975460125\n",
      "Accuracy: 0.9676635059567226\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "0L2XDbnoN5rN"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
