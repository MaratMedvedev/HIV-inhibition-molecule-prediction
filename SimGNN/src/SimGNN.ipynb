{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "The layers that we will use"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b6dbd239f2c92fc"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "\"\"\"Classes for SimGNN modules.\"\"\"\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "class AttentionModule(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    SimGNN Attention Module to make a pass on graph.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, args):\n",
    "        \"\"\"\n",
    "        :param args: Arguments object.\n",
    "        \"\"\"\n",
    "        super(AttentionModule, self).__init__()\n",
    "        self.args = args\n",
    "        self.setup_weights()\n",
    "        self.init_parameters()\n",
    "\n",
    "    def setup_weights(self):\n",
    "        \"\"\"\n",
    "        Defining weights.\n",
    "        \"\"\"\n",
    "        self.weight_matrix = torch.nn.Parameter(torch.Tensor(self.args.filters_3,\n",
    "                                                             self.args.filters_3))\n",
    "\n",
    "    def init_parameters(self):\n",
    "        \"\"\"\n",
    "        Initializing weights.\n",
    "        \"\"\"\n",
    "        torch.nn.init.xavier_uniform_(self.weight_matrix)\n",
    "\n",
    "    def forward(self, embedding):\n",
    "        \"\"\"\n",
    "        Making a forward propagation pass to create a graph level representation.\n",
    "        :param embedding: Result of the GCN.\n",
    "        :return representation: A graph level representation vector.\n",
    "        \"\"\"\n",
    "        global_context = torch.mean(torch.matmul(embedding, self.weight_matrix), dim=0)\n",
    "        transformed_global = torch.tanh(global_context)\n",
    "        sigmoid_scores = torch.sigmoid(torch.mm(embedding, transformed_global.view(-1, 1)))\n",
    "        representation = torch.mm(torch.t(embedding), sigmoid_scores)\n",
    "        return representation\n",
    "\n",
    "\n",
    "class TenorNetworkModule(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    SimGNN Tensor Network module to calculate similarity vector.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, args):\n",
    "        \"\"\"\n",
    "        :param args: Arguments object.\n",
    "        \"\"\"\n",
    "        super(TenorNetworkModule, self).__init__()\n",
    "        self.args = args\n",
    "        self.setup_weights()\n",
    "        self.init_parameters()\n",
    "\n",
    "    def setup_weights(self):\n",
    "        \"\"\"\n",
    "        Defining weights.\n",
    "        \"\"\"\n",
    "        self.weight_matrix = torch.nn.Parameter(torch.Tensor(self.args.filters_3,\n",
    "                                                             self.args.filters_3,\n",
    "                                                             self.args.tensor_neurons))\n",
    "\n",
    "        self.weight_matrix_block = torch.nn.Parameter(torch.Tensor(self.args.tensor_neurons,\n",
    "                                                                   2 * self.args.filters_3))\n",
    "        self.bias = torch.nn.Parameter(torch.Tensor(self.args.tensor_neurons, 1))\n",
    "\n",
    "    def init_parameters(self):\n",
    "        \"\"\"\n",
    "        Initializing weights.\n",
    "        \"\"\"\n",
    "        torch.nn.init.xavier_uniform_(self.weight_matrix)\n",
    "        torch.nn.init.xavier_uniform_(self.weight_matrix_block)\n",
    "        torch.nn.init.xavier_uniform_(self.bias)\n",
    "\n",
    "    def forward(self, embedding_1, embedding_2):\n",
    "        \"\"\"\n",
    "        Making a forward propagation pass to create a similarity vector.\n",
    "        :param embedding_1: Result of the 1st embedding after attention.\n",
    "        :param embedding_2: Result of the 2nd embedding after attention.\n",
    "        :return scores: A similarity score vector.\n",
    "        \"\"\"\n",
    "        scoring = torch.mm(torch.t(embedding_1), self.weight_matrix.view(self.args.filters_3, -1))\n",
    "        scoring = scoring.view(self.args.filters_3, self.args.tensor_neurons)\n",
    "        scoring = torch.mm(torch.t(scoring), embedding_2)\n",
    "        combined_representation = torch.cat((embedding_1, embedding_2))\n",
    "        block_scoring = torch.mm(self.weight_matrix_block, combined_representation)\n",
    "        scores = torch.nn.functional.relu(scoring + block_scoring + self.bias)\n",
    "        return scores"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T20:41:28.816016500Z",
     "start_time": "2023-12-09T20:41:28.741200200Z"
    }
   },
   "id": "ac9fb46c545ba82b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "SimGNN model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5f76df19ad27883"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "\"\"\"SimGNN class and runner.\"\"\"\n",
    "\n",
    "import glob\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "from torch_geometric.nn import GCNConv\n",
    "import math\n",
    "import json\n",
    "\n",
    "\n",
    "def calculate_loss(prediction, target):\n",
    "    \"\"\"\n",
    "    Calculating the squared loss on the normalized GED.\n",
    "    :param prediction: Predicted log value of GED.\n",
    "    :param target: Factual log transofmed GED.\n",
    "    :return score: Squared error.\n",
    "    \"\"\"\n",
    "    prediction = -math.log(prediction)\n",
    "    target = -math.log(target)\n",
    "    score = (prediction - target) ** 2\n",
    "    return score\n",
    "\n",
    "\n",
    "def calculate_normalized_ged(data):\n",
    "    \"\"\"\n",
    "    Calculating the normalized GED for a pair of graphs.\n",
    "    :param data: Data table.\n",
    "    :return norm_ged: Normalized GED score.\n",
    "    \"\"\"\n",
    "    norm_ged = data[\"ged\"] / (0.5 * (len(data[\"labels_1\"]) + len(data[\"labels_2\"])))\n",
    "    return norm_ged\n",
    "\n",
    "\n",
    "def process_pair(path):\n",
    "    \"\"\"\n",
    "    Reading a json file with a pair of graphs.\n",
    "    :param path: Path to a JSON file.\n",
    "    :return data: Dictionary with data.\n",
    "    \"\"\"\n",
    "    data = json.load(open(path))\n",
    "    return data\n",
    "\n",
    "\n",
    "class SimGNN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    SimGNN: A Neural Network Approach to Fast Graph Similarity Computation\n",
    "    https://arxiv.org/abs/1808.05689\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, args, number_of_labels):\n",
    "        \"\"\"\n",
    "        :param args: Arguments object.\n",
    "        :param number_of_labels: Number of node labels.\n",
    "        \"\"\"\n",
    "        super(SimGNN, self).__init__()\n",
    "        self.args = args\n",
    "        self.number_labels = number_of_labels\n",
    "        self.setup_layers()\n",
    "\n",
    "    def calculate_bottleneck_features(self):\n",
    "        \"\"\"\n",
    "        Deciding the shape of the bottleneck layer.\n",
    "        \"\"\"\n",
    "        if self.args.histogram == True:\n",
    "            self.feature_count = self.args.tensor_neurons + self.args.bins\n",
    "        else:\n",
    "            self.feature_count = self.args.tensor_neurons\n",
    "\n",
    "    def setup_layers(self):\n",
    "        \"\"\"\n",
    "        Creating the layers.\n",
    "        \"\"\"\n",
    "        self.calculate_bottleneck_features()\n",
    "        self.convolution_1 = GCNConv(self.number_labels, self.args.filters_1)\n",
    "        self.convolution_2 = GCNConv(self.args.filters_1, self.args.filters_2)\n",
    "        self.convolution_3 = GCNConv(self.args.filters_2, self.args.filters_3)\n",
    "        self.attention = AttentionModule(self.args)\n",
    "        self.tensor_network = TenorNetworkModule(self.args)\n",
    "        self.fully_connected_first = torch.nn.Linear(self.feature_count,\n",
    "                                                     self.args.bottle_neck_neurons)\n",
    "        self.scoring_layer = torch.nn.Linear(self.args.bottle_neck_neurons, 1)\n",
    "\n",
    "    def calculate_histogram(self, abstract_features_1, abstract_features_2):\n",
    "        \"\"\"\n",
    "        Calculate histogram from similarity matrix.\n",
    "        :param abstract_features_1: Feature matrix for graph 1.\n",
    "        :param abstract_features_2: Feature matrix for graph 2.\n",
    "        :return hist: Histsogram of similarity scores.\n",
    "        \"\"\"\n",
    "        scores = torch.mm(abstract_features_1, abstract_features_2).detach()\n",
    "        scores = scores.view(-1, 1)\n",
    "        hist = torch.histc(scores, bins=self.args.bins)\n",
    "        hist = hist / torch.sum(hist)\n",
    "        hist = hist.view(1, -1)\n",
    "        return hist\n",
    "\n",
    "    def convolutional_pass(self, edge_index, features):\n",
    "        \"\"\"\n",
    "        Making convolutional pass.\n",
    "        :param edge_index: Edge indices.\n",
    "        :param features: Feature matrix.\n",
    "        :return features: Absstract feature matrix.\n",
    "        \"\"\"\n",
    "        features = self.convolution_1(features, edge_index)\n",
    "        features = torch.nn.functional.relu(features)\n",
    "        features = torch.nn.functional.dropout(features,\n",
    "                                               p=self.args.dropout,\n",
    "                                               training=self.training)\n",
    "\n",
    "        features = self.convolution_2(features, edge_index)\n",
    "        features = torch.nn.functional.relu(features)\n",
    "        features = torch.nn.functional.dropout(features,\n",
    "                                               p=self.args.dropout,\n",
    "                                               training=self.training)\n",
    "\n",
    "        features = self.convolution_3(features, edge_index)\n",
    "        return features\n",
    "\n",
    "    def forward(self, data):\n",
    "        \"\"\"\n",
    "        Forward pass with graphs.\n",
    "        :param data: Data dictiyonary.\n",
    "        :return score: Similarity score.\n",
    "        \"\"\"\n",
    "        edge_index_1 = data[\"edge_index_1\"]\n",
    "        edge_index_2 = data[\"edge_index_2\"]\n",
    "        features_1 = data[\"features_1\"]\n",
    "        features_2 = data[\"features_2\"]\n",
    "\n",
    "        abstract_features_1 = self.convolutional_pass(edge_index_1, features_1)\n",
    "        abstract_features_2 = self.convolutional_pass(edge_index_2, features_2)\n",
    "\n",
    "        if self.args.histogram == True:\n",
    "            hist = self.calculate_histogram(abstract_features_1,\n",
    "                                            torch.t(abstract_features_2))\n",
    "\n",
    "        pooled_features_1 = self.attention(abstract_features_1)\n",
    "        pooled_features_2 = self.attention(abstract_features_2)\n",
    "        scores = self.tensor_network(pooled_features_1, pooled_features_2)\n",
    "        scores = torch.t(scores)\n",
    "\n",
    "        if self.args.histogram == True:\n",
    "            scores = torch.cat((scores, hist), dim=1).view(1, -1)\n",
    "\n",
    "        scores = torch.nn.functional.relu(self.fully_connected_first(scores))\n",
    "        score = torch.sigmoid(self.scoring_layer(scores))\n",
    "        return score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T20:41:28.816016500Z",
     "start_time": "2023-12-09T20:41:28.759574800Z"
    }
   },
   "id": "d38457da6bc2b7e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "SimGNN model trainer\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "771d88ac59b17cdc"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "class SimGNNTrainer(object):\n",
    "    \"\"\"\n",
    "    SimGNN model trainer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, args):\n",
    "        \"\"\"\n",
    "        :param args: Arguments object.\n",
    "        \"\"\"\n",
    "        self.args = args\n",
    "        self.initial_label_enumeration()\n",
    "        self.setup_model()\n",
    "\n",
    "    def setup_model(self):\n",
    "        \"\"\"\n",
    "        Creating a SimGNN.\n",
    "        \"\"\"\n",
    "        self.model = SimGNN(self.args, self.number_of_labels)\n",
    "\n",
    "    def initial_label_enumeration(self):\n",
    "        \"\"\"\n",
    "        Collecting the unique node idsentifiers.\n",
    "        \"\"\"\n",
    "        print(\"\\nEnumerating unique labels.\\n\")\n",
    "        print(self.args.training_graphs)\n",
    "        self.training_graphs = glob.glob(self.args.training_graphs + \"*.json\")\n",
    "        self.testing_graphs = glob.glob(self.args.testing_graphs + \"*.json\")\n",
    "        graph_pairs = self.training_graphs + self.testing_graphs\n",
    "        self.global_labels = set()\n",
    "        for graph_pair in tqdm(graph_pairs):\n",
    "            data = process_pair(graph_pair)\n",
    "            self.global_labels = self.global_labels.union(set(data[\"labels_1\"]))\n",
    "            self.global_labels = self.global_labels.union(set(data[\"labels_2\"]))\n",
    "        self.global_labels = sorted(self.global_labels)\n",
    "        self.global_labels = {val: index for index, val in enumerate(self.global_labels)}\n",
    "        self.number_of_labels = len(self.global_labels)\n",
    "\n",
    "    def create_batches(self):\n",
    "        \"\"\"\n",
    "        Creating batches from the training graph list.\n",
    "        :return batches: List of lists with batches.\n",
    "        \"\"\"\n",
    "        random.shuffle(self.training_graphs)\n",
    "        batches = []\n",
    "        for graph in range(0, len(self.training_graphs), self.args.batch_size):\n",
    "            batches.append(self.training_graphs[graph:graph + self.args.batch_size])\n",
    "        return batches\n",
    "\n",
    "    def transfer_to_torch(self, data):\n",
    "        \"\"\"\n",
    "        Transferring the data to torch and creating a hash table.\n",
    "        Including the indices, features and target.\n",
    "        :param data: Data dictionary.\n",
    "        :return new_data: Dictionary of Torch Tensors.\n",
    "        \"\"\"\n",
    "        new_data = dict()\n",
    "        edges_1 = data[\"graph_1\"] + [[y, x] for x, y in data[\"graph_1\"]]\n",
    "\n",
    "        edges_2 = data[\"graph_2\"] + [[y, x] for x, y in data[\"graph_2\"]]\n",
    "\n",
    "        edges_1 = torch.from_numpy(np.array(edges_1, dtype=np.int64).T).type(torch.long)\n",
    "        edges_2 = torch.from_numpy(np.array(edges_2, dtype=np.int64).T).type(torch.long)\n",
    "\n",
    "        features_1, features_2 = [], []\n",
    "\n",
    "        for n in data[\"labels_1\"]:\n",
    "            features_1.append([1.0 if self.global_labels[n] == i else 0.0 for i in self.global_labels.values()])\n",
    "\n",
    "        for n in data[\"labels_2\"]:\n",
    "            features_2.append([1.0 if self.global_labels[n] == i else 0.0 for i in self.global_labels.values()])\n",
    "\n",
    "        features_1 = torch.FloatTensor(np.array(features_1))\n",
    "        features_2 = torch.FloatTensor(np.array(features_2))\n",
    "\n",
    "        new_data[\"edge_index_1\"] = edges_1\n",
    "        new_data[\"edge_index_2\"] = edges_2\n",
    "\n",
    "        new_data[\"features_1\"] = features_1\n",
    "        new_data[\"features_2\"] = features_2\n",
    "\n",
    "        norm_ged = data[\"ged\"] / (0.5 * (len(data[\"labels_1\"]) + len(data[\"labels_2\"])))\n",
    "\n",
    "        new_data[\"target\"] = torch.from_numpy(np.exp(-norm_ged).reshape(1, 1)).view(-1).float()\n",
    "        return new_data\n",
    "\n",
    "    def process_batch(self, batch):\n",
    "        \"\"\"\n",
    "        Forward pass with a batch of data.\n",
    "        :param batch: Batch of graph pair locations.\n",
    "        :return loss: Loss on the batch.\n",
    "        \"\"\"\n",
    "        self.optimizer.zero_grad()\n",
    "        losses = 0\n",
    "        for graph_pair in batch:\n",
    "            data = process_pair(graph_pair)\n",
    "            data = self.transfer_to_torch(data)\n",
    "            target = data[\"target\"]\n",
    "            prediction = self.model(data)\n",
    "            losses = losses + torch.nn.functional.mse_loss(data[\"target\"], prediction)\n",
    "        losses.backward(retain_graph=True)\n",
    "        self.optimizer.step()\n",
    "        loss = losses.item()\n",
    "        return loss\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        Fitting a model.\n",
    "        \"\"\"\n",
    "        print(\"\\nModel training.\\n\")\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(),\n",
    "                                          lr=self.args.learning_rate,\n",
    "                                          weight_decay=self.args.weight_decay)\n",
    "\n",
    "        self.model.train()\n",
    "        epochs = trange(self.args.epochs, leave=True, desc=\"Epoch\")\n",
    "        for epoch in epochs:\n",
    "            batches = self.create_batches()\n",
    "            self.loss_sum = 0\n",
    "            main_index = 0\n",
    "            for index, batch in tqdm(enumerate(batches), total=len(batches), desc=\"Batches\"):\n",
    "                loss_score = self.process_batch(batch)\n",
    "                main_index = main_index + len(batch)\n",
    "                self.loss_sum = self.loss_sum + loss_score * len(batch)\n",
    "                loss = self.loss_sum / main_index\n",
    "                epochs.set_description(\"Epoch (Loss=%g)\" % round(loss, 5))\n",
    "\n",
    "    def score(self):\n",
    "        \"\"\"\n",
    "        Scoring on the test set.\n",
    "        \"\"\"\n",
    "        print(\"\\n\\nModel evaluation.\\n\")\n",
    "        self.model.eval()\n",
    "        self.scores = []\n",
    "        self.ground_truth = []\n",
    "        for graph_pair in tqdm(self.testing_graphs):\n",
    "            data = process_pair(graph_pair)\n",
    "            self.ground_truth.append(calculate_normalized_ged(data))\n",
    "            data = self.transfer_to_torch(data)\n",
    "            target = data[\"target\"]\n",
    "            prediction = self.model(data)\n",
    "            self.scores.append(calculate_loss(prediction, target))\n",
    "        self.print_evaluation()\n",
    "\n",
    "    def print_evaluation(self):\n",
    "        \"\"\"\n",
    "        Printing the error rates.\n",
    "        \"\"\"\n",
    "\n",
    "        norm_ged_mean = np.mean(self.ground_truth)\n",
    "        base_error = np.mean([(n - norm_ged_mean) ** 2 for n in self.ground_truth])\n",
    "        model_error = np.mean(self.scores)\n",
    "        print(\"\\nBaseline error: \" + str(round(base_error, 5)) + \".\")\n",
    "        print(\"\\nModel test error: \" + str(round(model_error, 5)) + \".\")\n",
    "\n",
    "    def save(self):\n",
    "        torch.save(self.model.state_dict(), self.args.save_path)\n",
    "\n",
    "    def load(self):\n",
    "        self.model.load_state_dict(torch.load(self.args.load_path))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T20:41:28.816016500Z",
     "start_time": "2023-12-09T20:41:28.797925800Z"
    }
   },
   "id": "b185b301d765c5d7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Args assignment"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e9525920c853f8d7"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "default_agrs = {'training_graphs': './dataset/train/',\n",
    "                'testing_graphs': './dataset/test/',\n",
    "                'epochs': 5,\n",
    "                'filters_1': 128,\n",
    "                'filters_2': 64,\n",
    "                'filters_3': 32,\n",
    "                'tensor_neurons': 16,\n",
    "                'bottle_neck_neurons': 16,\n",
    "                'batch_size': 128,\n",
    "                'bins': 16,\n",
    "                'dropout': 0.5,\n",
    "                'learning_rate': 0.001,\n",
    "                'weight_decay': 0.0005,\n",
    "                'histogram': False,\n",
    "                'save_path': None,\n",
    "                'load_path': None\n",
    "                }\n",
    "\n",
    "args = argparse.Namespace(**default_agrs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T20:41:28.844801700Z",
     "start_time": "2023-12-09T20:41:28.816016500Z"
    }
   },
   "id": "25c2e1da0e0ddb19"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enumerating unique labels.\n",
      "\n",
      "./dataset/train/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 3195.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Batches:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[AC:\\Users\\freid\\AppData\\Local\\Temp\\ipykernel_22928\\2898697882.py:99: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  losses = losses + torch.nn.functional.mse_loss(data[\"target\"], prediction)\n",
      "Epoch (Loss=1.4083):   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.91it/s]\u001B[A\n",
      "Epoch (Loss=1.4083):  20%|██        | 1/5 [00:00<00:00,  4.91it/s]\n",
      "Epoch (Loss=1.33147):  20%|██        | 1/5 [00:00<00:00,  4.91it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s]\u001B[A\n",
      "Epoch (Loss=1.33147):  40%|████      | 2/5 [00:00<00:00,  5.13it/s]\n",
      "Epoch (Loss=1.24657):  40%|████      | 2/5 [00:00<00:00,  5.13it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s]\u001B[A\n",
      "Epoch (Loss=1.24657):  60%|██████    | 3/5 [00:00<00:00,  5.31it/s]\n",
      "Epoch (Loss=1.21541):  60%|██████    | 3/5 [00:00<00:00,  5.31it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.33it/s]\u001B[A\n",
      "Epoch (Loss=1.21541):  80%|████████  | 4/5 [00:00<00:00,  5.22it/s]\n",
      "Epoch (Loss=1.10275):  80%|████████  | 4/5 [00:00<00:00,  5.22it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.22it/s]\u001B[A\n",
      "Epoch (Loss=1.10275): 100%|██████████| 5/5 [00:00<00:00,  5.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Model evaluation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 99.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline error: 0.0.\n",
      "\n",
      "Model test error: 3.45135.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainer = SimGNNTrainer(args)\n",
    "trainer.fit()\n",
    "trainer.score()\n",
    "if args.save_path:\n",
    "    trainer.save()\n",
    "model = trainer.model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T20:41:29.900782900Z",
     "start_time": "2023-12-09T20:41:28.834433600Z"
    }
   },
   "id": "a397e36bf71ab896"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5080]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "test_data = {\"labels_1\": [\"11\", \"11\", \"9\"],\n",
    "             \"labels_2\": [\"8\", \"11\", \"5\"],\n",
    "             \"graph_2\": [[0, 1], [0, 2]], \"ged\": 11,\n",
    "             \"graph_1\": [[0, 1], [0, 2]]}\n",
    "tst = trainer.transfer_to_torch(test_data)\n",
    "print(model(tst))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T20:41:29.917526500Z",
     "start_time": "2023-12-09T20:41:29.842969500Z"
    }
   },
   "id": "37a8932b792ec92a"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T20:41:29.918045900Z",
     "start_time": "2023-12-09T20:41:29.874606700Z"
    }
   },
   "id": "5921e46d8c0c4b21"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
